{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Naive Bayes to classify Reddit comments as either \"up\" or \"down\" in terms of score (net of up and down votes).  I am using the personalfinance subreddit November 2015 as input.  Initial queries to calculate percentile values and extract only extreme \"up\" or \"down\" voted comments (i.e., below 3rd and above 97th percentiles) done through Google BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nltk\n",
    "# import csv\n",
    "import unicodecsv\n",
    "import re\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from ggplot import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import codecs\n",
    "import cStringIO\n",
    "from app.helpers import WordUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from CSV file downloaded from Google bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary helper functions for reading Unicode CSV files. See https://docs.python.org/2/library/csv.html\n",
    "\n",
    "I WILL TRY IT WITH UNICODECSV AND SEE HOW IT WORKS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/results-20151224-154845.csv', 'rb') as f:\n",
    "    # reader = UnicodeReader(f)\n",
    "    reader = unicodecsv.reader(f, encoding='utf-8')\n",
    "    pflist = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('data/results-20151224-154845.csv', 'rb')\n",
    "reader = unicodecsv.reader(f, encoding='utf-8')\n",
    "row = next(reader)\n",
    "row = next(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pflist[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "delete header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pflist[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "map to just body and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pflist_body_score = map(lambda line: [line[0], line[11]], pflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pflist_body_score[1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanup(body):\n",
    "    body = re.sub(\"&gt;\", \">\", body) # Recode HTML codes\n",
    "    body = re.sub(\"&lt;\", \"<\", body)\n",
    "    body = re.sub(\"&amp;\", \"&\", body)\n",
    "    body = re.sub(\"&nbsp;\", \" \", body)\n",
    "    body = re.sub(ur\"^[deleted]$\", \"\", body) # Remove deleted\n",
    "    body = re.sub(\"http[[:alnum:][:punct:]]*\", \" \", body) # Remove URL\n",
    "    body = re.sub(\"/r/[[:alnum:]]+|/u/[[:alnum:]]+\", \" \", body) # Remove /r/subreddit, /u/user\n",
    "    # body = re.sub(\"(>.*?\\\\n\\\\n)+\", \" \", body) # Remove quoted comments\n",
    "    body = re.sub(\"[[:cntrl:]]\", \" \", body) # Remove control characters (\\n, \\b)\n",
    "    body = re.sub(\"'\", \"\", body) # Remove single quotation marks (contractions)\n",
    "    body = re.sub(\"[[:punct:]]\", \" \", body) # Remove punctuation\n",
    "    body = re.sub(\"\\\\s+\", \" \", body) # Replace multiple spaces with single space\n",
    "    body = body.strip() # doesn't work for unicode\n",
    "    # body = body.decode('utf-8').strip()\n",
    "    body = body.lower() # Lower case\n",
    "    return body # Return body (cleaned up text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label(score):\n",
    "    if int(score) <= -1: return 'neg'\n",
    "    else: return 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up body, change numerical score to pos or neg\n",
    "pflist_clean = map(lambda line: [cleanup(line[0]), label(line[1])], pflist_body_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pflist_clean[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(pflist_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pflist_clean[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pflist_unicode = map(lambda line: [unicode(line[0]), line[1]], pflist_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pflist_tokens = map(lambda line: [nltk.word_tokenize(line[0]), line[1]], pflist_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pflist_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SEE ABOVE.  u'[deleted]' is still there.  cleanup() isn't working.  I need to set up test to debug and make sure it workds- TDD!!!  The book \"Python Cookbook\" might have the answers for doing regex with Unicode, but check free sources first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/test.csv', 'rb') as f:\n",
    "    # reader = UnicodeReader(f)\n",
    "    reader = unicodecsv.reader(f, encoding='utf-8')\n",
    "    pflist = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
